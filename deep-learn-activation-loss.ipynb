{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.0.0-rc1\n",
    "#!pip install tensorflow-gpu==2.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and do the preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "input_dim = 784  # 28*28\n",
    "output_dim = nb_classes = 10\n",
    "batch_size = 128\n",
    "nb_epoch = 20\n",
    "\n",
    "X_train = X_train.reshape(60000, input_dim)\n",
    "X_test = X_test.reshape(10000, input_dim)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, one-hot code your target variable using the `to_categorical()` function from the `keras.utils` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check the size of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) In this task, you'll implement several ANN models with different activation functions. Specifically, do the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the tanh activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "tanh_model = Sequential()\n",
    "\n",
    "tanh_model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n",
    "tanh_model.add(Dense(64, activation=\"tanh\"))\n",
    "tanh_model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tanh_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compole the model\n",
    "tanh_model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002A0D0D1E828> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002A0D0D1E828> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.0154 - accuracy: 0.7561\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.5131 - accuracy: 0.8722\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.4162 - accuracy: 0.8900\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3699 - accuracy: 0.8988\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.3413 - accuracy: 0.9048\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.3211 - accuracy: 0.9093\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.3054 - accuracy: 0.9133\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2926 - accuracy: 0.9167\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2817 - accuracy: 0.9191\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2721 - accuracy: 0.9220\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2636 - accuracy: 0.9240\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2557 - accuracy: 0.9262\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2484 - accuracy: 0.9286\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2415 - accuracy: 0.9302\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2353 - accuracy: 0.9321\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2293 - accuracy: 0.9341\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2237 - accuracy: 0.9358\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2183 - accuracy: 0.9372\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2133 - accuracy: 0.9390\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2083 - accuracy: 0.9406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a0d0d2ab88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "tanh_model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.20621993271410466\n",
      "Test accuracy: 0.9414\n"
     ]
    }
   ],
   "source": [
    "# Print the model results\n",
    "score = tanh_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the sigmoid activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "sig_model = Sequential()\n",
    "\n",
    "sig_model.add(Dense(128, input_shape=(784,), activation=\"sigmoid\"))\n",
    "sig_model.add(Dense(64, activation=\"sigmoid\"))\n",
    "sig_model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sig_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compole the model\n",
    "sig_model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002A0DC997678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002A0DC997678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.2931 - accuracy: 0.1413\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2274 - accuracy: 0.3208\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.1593 - accuracy: 0.4775\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 2.0640 - accuracy: 0.5705\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.9315 - accuracy: 0.6026\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.7628 - accuracy: 0.6310\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.5752 - accuracy: 0.6619\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.3937 - accuracy: 0.6897\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.2361 - accuracy: 0.7218\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.1070 - accuracy: 0.7471\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0023 - accuracy: 0.7705\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.9167 - accuracy: 0.7899\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8457 - accuracy: 0.8039\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.7859 - accuracy: 0.8177\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.7351 - accuracy: 0.8292\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.6915 - accuracy: 0.8372\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.6541 - accuracy: 0.8452\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.6217 - accuracy: 0.8509\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.5934 - accuracy: 0.8563\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.5687 - accuracy: 0.8607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a0dc988388>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "sig_model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.5442446291446685\n",
      "Test accuracy: 0.8672\n"
     ]
    }
   ],
   "source": [
    "# Print the model results\n",
    "score = sig_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the ReLU activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "relu_model = Sequential()\n",
    "\n",
    "relu_model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
    "relu_model.add(Dense(64, activation=\"relu\"))\n",
    "relu_model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "relu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compole the model\n",
    "relu_model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002A0DE029168> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002A0DE029168> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.2649 - accuracy: 0.6892\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.4990 - accuracy: 0.8674\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.3897 - accuracy: 0.8922\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.3428 - accuracy: 0.9034\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3140 - accuracy: 0.9114\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2926 - accuracy: 0.9173\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2757 - accuracy: 0.9224\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2613 - accuracy: 0.9265\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2491 - accuracy: 0.9296\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2378 - accuracy: 0.9334\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2278 - accuracy: 0.9357\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.2187 - accuracy: 0.9386\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2106 - accuracy: 0.9410\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2029 - accuracy: 0.9430\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1959 - accuracy: 0.9449\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1894 - accuracy: 0.9470\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.1831 - accuracy: 0.9487\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1775 - accuracy: 0.9505\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1721 - accuracy: 0.9524\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1670 - accuracy: 0.9533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a0dc592cc8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "relu_model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.1644923143029213\n",
      "Test accuracy: 0.9514\n"
     ]
    }
   ],
   "source": [
    "# Print the model results\n",
    "score = relu_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the results of each model. Which activation function performed best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tanh = 94%\n",
    "* sigmoid = 86%\n",
    "* reLU = 95%\n",
    "\n",
    "The reLU model performed the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) In this task, you'll implement the ANN models specified below. For each, use the hinge loss function as the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the tanh activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "tanh_model = Sequential()\n",
    "\n",
    "tanh_model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n",
    "tanh_model.add(Dense(64, activation=\"tanh\"))\n",
    "tanh_model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tanh_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compole the model\n",
    "tanh_model.compile(optimizer='sgd', loss='categorical_hinge',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1430: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002A0DC8AAEE8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002A0DC8AAEE8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.9863 - accuracy: 0.4142\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.7743 - accuracy: 0.7005\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.5852 - accuracy: 0.7995\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.4630 - accuracy: 0.8465\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.3885 - accuracy: 0.8676\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.3425 - accuracy: 0.8777\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.3120 - accuracy: 0.8835\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2901 - accuracy: 0.8888\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2734 - accuracy: 0.8929\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2601 - accuracy: 0.8970\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2492 - accuracy: 0.9002\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2400 - accuracy: 0.9028\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2321 - accuracy: 0.9053\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2251 - accuracy: 0.9071\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2190 - accuracy: 0.9092\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2135 - accuracy: 0.9109\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2084 - accuracy: 0.9124\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2039 - accuracy: 0.9140\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1996 - accuracy: 0.9154\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1957 - accuracy: 0.9171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a0de756448>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "tanh_model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.1893198136627674\n",
      "Test accuracy: 0.9207\n"
     ]
    }
   ],
   "source": [
    "# Print the model results\n",
    "score = tanh_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the sigmoid activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "sig_model = Sequential()\n",
    "\n",
    "sig_model.add(Dense(128, input_shape=(784,), activation=\"sigmoid\"))\n",
    "sig_model.add(Dense(64, activation=\"sigmoid\"))\n",
    "sig_model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sig_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compole the model\n",
    "sig_model.compile(optimizer='sgd', loss='categorical_hinge',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002A0DFED61F8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002A0DFED61F8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.0101 - accuracy: 0.0932\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0036 - accuracy: 0.1152\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.0029 - accuracy: 0.1576\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.0024 - accuracy: 0.2051\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0019 - accuracy: 0.2569\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0014 - accuracy: 0.3174\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.0010 - accuracy: 0.3773\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.0007 - accuracy: 0.4237\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 1.0004 - accuracy: 0.4629\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0000 - accuracy: 0.4948\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.9997 - accuracy: 0.5232\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.9995 - accuracy: 0.5468\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.9992 - accuracy: 0.5683\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.9989 - accuracy: 0.5865\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.9987 - accuracy: 0.6009\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.9984 - accuracy: 0.6153\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.9982 - accuracy: 0.6280\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.9979 - accuracy: 0.6375\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.9977 - accuracy: 0.6471\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.9975 - accuracy: 0.6556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a0dfec6bc8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "sig_model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.997283199596405\n",
      "Test accuracy: 0.6644\n"
     ]
    }
   ],
   "source": [
    "# Print the model results\n",
    "score = sig_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the ReLU activation function for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "relu_model = Sequential()\n",
    "\n",
    "relu_model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
    "relu_model.add(Dense(64, activation=\"relu\"))\n",
    "relu_model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "relu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compole the model\n",
    "relu_model.compile(optimizer='sgd', loss='categorical_hinge',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002A0E0664A68> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002A0E0664A68> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.0115 - accuracy: 0.3374\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.9746 - accuracy: 0.5459\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.8689 - accuracy: 0.5833\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.6937 - accuracy: 0.7100\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.5272 - accuracy: 0.8062\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.4122 - accuracy: 0.8554\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.3387 - accuracy: 0.8759\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2949 - accuracy: 0.8867\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2672 - accuracy: 0.8932\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2481 - accuracy: 0.8982\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2337 - accuracy: 0.9028\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2224 - accuracy: 0.9063\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2131 - accuracy: 0.9089\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2053 - accuracy: 0.9118\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1985 - accuracy: 0.9144\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1925 - accuracy: 0.9167\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1870 - accuracy: 0.9186\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1821 - accuracy: 0.9207\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1778 - accuracy: 0.9222\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.1738 - accuracy: 0.9238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a0e067bb88>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "relu_model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.16599102637767793\n",
      "Test accuracy: 0.9272\n"
     ]
    }
   ],
   "source": [
    "# Print the model results\n",
    "score = relu_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the results of each model with the result of the same model from the previous task. Which loss function performed best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With crossentropy loss:\n",
    "* tanh = 94%\n",
    "* sigmoid = 86%\n",
    "* reLU = 95%\n",
    "\n",
    "With hinge loss:\n",
    "* tanh = 92%\n",
    "* sigmoid = 66%\n",
    "* reLU = 92%\n",
    "\n",
    "### All 3 activation types performed worse using hinge loss\n",
    "### tanh and reLU performed the best using either crossentropy or hinge loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
